{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using text of 'Alice in Wonderland' ebook from https://www.gutenberg.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/11/11-0.txt\"\n",
    "alice = requests.get(url)\n",
    "print(alice.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to plot word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_word_frequency(words, top_n=10):\n",
    "    word_freq = FreqDist(words)\n",
    "    labels = [element[0] for element in word_freq.most_common(top_n)]\n",
    "    counts = [element[1] for element in word_freq.most_common(top_n)]\n",
    "    plot = sns.barplot(labels, counts)\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot words frequencies present in the gutenberg corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_words = alice.text.split()\n",
    "plot_word_frequency(alice_words, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import stopwords from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the list of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stopwords.words('spanis'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove stopwords from the following piece of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"the great aim of education is not knowledge but action\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break text into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_words = sample_text.split()\n",
    "print(sample_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_words = [word for word in sample_words if word not in stopwords.words('english')]\n",
    "print(sample_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join words back to sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \" \".join(sample_words)\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stopwords in the genesis corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stops = [word for word in alice_words if word not in stopwords.words(\"english\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_frequency(no_stops, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other things that can be done\n",
    "* Need to change tokens to lower case\n",
    "* Need to get rid of punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3rd highest frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1214\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.gutenberg.org/files/16/16-0.txt\"\n",
    "peter_pan = requests.get(url).text\n",
    "\n",
    "peter_pan_words = peter_pan.split() # write your code here\n",
    "\n",
    "\n",
    "word_frequency = FreqDist(peter_pan_words)# write your code here\n",
    "\n",
    "\n",
    "freq = word_frequency.most_common(3)[2][1]\n",
    "\n",
    "\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Highest Frequency after removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.gutenberg.org/files/16/16-0.txt\"\n",
    "peter_pan = requests.get(url).text\n",
    "\n",
    "# break the book into different words using the split() method\n",
    "peter_pan_words = peter_pan.split()\n",
    "\n",
    "# build frequency distribution using NLTK's FreqDist() function\n",
    "word_frequency = FreqDist(peter_pan_words)\n",
    "\n",
    "# extract nltk stop word list\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "# remove 'stopwords' from 'peter_pan_words'\n",
    "no_stops = [ x for x in peter_pan_words if x not in stopwords ] # write code here\n",
    "\n",
    "# create word frequency of no_stops\n",
    "word_frequency = FreqDist(no_stops)# write code here\n",
    "\n",
    "# extract the most frequent word and its frequency\n",
    "frequency = word_frequency.most_common(1)[0][1]\n",
    "\n",
    "# print the third most frequent word - don't change the following code, it is used to evaluate the code\n",
    "print(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
